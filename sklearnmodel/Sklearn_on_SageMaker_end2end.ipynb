{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Develop, Train, Optimize and Deploy Scikit-Learn Random Forest\n",
    "\n",
    "> *This notebook should work well with the `Python 3 (Data Science 3.0)` kernel on SageMaker Studio, or `conda_python3` on classic SageMaker Notebook Instances*\n",
    "\n",
    "In this notebook we show how to use Amazon SageMaker to develop, train, tune and deploy a Random Forest model based using the popular ML framework [Scikit-Learn](https://scikit-learn.org/stable/index.html).\n",
    "\n",
    "The example uses the *California Housing dataset* (provided by Scikit-Learn) - more details of which can be found [here](https://inria.github.io/scikit-learn-mooc/python_scripts/datasets_california_housing.html).\n",
    "\n",
    "To understand the code, you might also find it useful to refer to:\n",
    "\n",
    "* The guide on [Using Scikit-Learn with the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/using_sklearn.html)\n",
    "* The API doc for [Scikit-Learn classes in the SageMaker Python SDK](https://sagemaker.readthedocs.io/en/stable/sagemaker.sklearn.html)\n",
    "* The [SageMaker reference for Boto3](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/sagemaker.html#client) (The general AWS SDK for Python, including low-level bindings for SageMaker as well as many other AWS services)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set up libraries and environment\n",
    "\n",
    "The SageMaker kernel mentioned above (check you're running with the right one!) should already include all the libraries needed for this notebook - so we can start out by importing the dependencies and setting up basic configurations, like the current [AWS Region](https://aws.amazon.com/about-aws/global-infrastructure/) and target [Amazon S3 bucket](https://aws.amazon.com/s3/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "Using bucket sagemaker-us-east-1-547283773376\n"
     ]
    }
   ],
   "source": [
    "# Python Built-Ins:\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import boto3  # General-purpose AWS SDK for Python\n",
    "import numpy as np  # Tools for working with numeric arrays\n",
    "import pandas as pd  # Tools for warking with data tables (dataframes)\n",
    "import sagemaker  # High-level SDK for Amazon SageMaker in particular\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "sm_boto3 = boto3.client(\"sagemaker\")\n",
    "sess = sagemaker.Session()\n",
    "region = sess.boto_session.region_name\n",
    "bucket = sess.default_bucket()  # this could also be a hard-coded bucket name\n",
    "\n",
    "print(f\"Using bucket {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data\n",
    "\n",
    "Next, we'll load our raw example dataset from SKLearn and prepare it into the format the training job will use: A separate CSV for training and for validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.2143</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.288235</td>\n",
       "      <td>0.973529</td>\n",
       "      <td>860.0</td>\n",
       "      <td>2.529412</td>\n",
       "      <td>33.81</td>\n",
       "      <td>-118.12</td>\n",
       "      <td>2.285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3468</td>\n",
       "      <td>42.0</td>\n",
       "      <td>6.364322</td>\n",
       "      <td>1.087940</td>\n",
       "      <td>957.0</td>\n",
       "      <td>2.404523</td>\n",
       "      <td>37.16</td>\n",
       "      <td>-121.98</td>\n",
       "      <td>2.799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.9191</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.110063</td>\n",
       "      <td>1.059748</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2.235849</td>\n",
       "      <td>38.45</td>\n",
       "      <td>-122.69</td>\n",
       "      <td>1.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.3703</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.990196</td>\n",
       "      <td>1159.0</td>\n",
       "      <td>2.272549</td>\n",
       "      <td>34.16</td>\n",
       "      <td>-118.41</td>\n",
       "      <td>4.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.3684</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.795858</td>\n",
       "      <td>1.035503</td>\n",
       "      <td>706.0</td>\n",
       "      <td>2.088757</td>\n",
       "      <td>38.57</td>\n",
       "      <td>-121.33</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  4.2143      37.0  5.288235   0.973529       860.0  2.529412     33.81   \n",
       "1  5.3468      42.0  6.364322   1.087940       957.0  2.404523     37.16   \n",
       "2  3.9191      36.0  6.110063   1.059748       711.0  2.235849     38.45   \n",
       "3  6.3703      32.0  6.000000   0.990196      1159.0  2.272549     34.16   \n",
       "4  2.3684      17.0  4.795858   1.035503       706.0  2.088757     38.57   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -118.12   2.285  \n",
       "1    -121.98   2.799  \n",
       "2    -122.69   1.830  \n",
       "3    -118.41   4.658  \n",
       "4    -121.33   1.500  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_california_housing()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data.data, data.target, test_size=0.25, random_state=42\n",
    ")\n",
    "\n",
    "trainX = pd.DataFrame(X_train, columns=data.feature_names)\n",
    "trainX[\"target\"] = y_train\n",
    "\n",
    "testX = pd.DataFrame(X_test, columns=data.feature_names)\n",
    "testX[\"target\"] = y_test\n",
    "\n",
    "trainX.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create directories\n",
    "os.makedirs(\"data/train\", exist_ok=True)\n",
    "os.makedirs(\"data/test\", exist_ok=True)\n",
    "os.makedirs(\"src\", exist_ok=True)\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "\n",
    "# save data as csv\n",
    "trainX.to_csv(\"data/train/train.csv\")\n",
    "testX.to_csv(\"data/test/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a training script\n",
    "\n",
    "The SageMaker Scikit-Learn [Framework Container](https://docs.aws.amazon.com/sagemaker/latest/dg/pre-built-docker-containers-scikit-learn-spark.html) provides the basic runtime, and we as users specify the actual training steps to run as a script file (or even a folder of several, perhaps including a `requirements.txt`).\n",
    "\n",
    "The below code initializes a [`src/main.py`](src/main.py) file from here in the notebook. You can also create Python scripts and other files from the launcher or the File menu.\n",
    "\n",
    "In this example, the same file will be used at training time (run as as script), and at inference time (imported as a [module](https://docs.python.org/3/tutorial/modules.html)) - So below we:\n",
    "\n",
    "- Define some specific **inference functions** to override default behavior (e.g. `model_fn()`), and\n",
    "- Enclose the **training entry point** in an `if __name__ == '__main__'` [guard clause](https://docs.python.org/3/library/__main__.html) so it only executes when the module is run as a script.\n",
    "\n",
    "You can find detailed guidance in the documentation on [Preparing a Scikit-Learn training script](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#prepare-a-scikit-learn-training-script) (for training) and the [SageMaker Scikit-Learn model server](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#sagemaker-scikit-learn-model-server) (for inference)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/main.py\n",
    "# Python Built-Ins:\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "# External Dependencies:\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# ---- INFERENCE FUNCTIONS ----\n",
    "def model_fn(model_dir):\n",
    "    model = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # ---- TRAINING ENTRY POINT ----\n",
    "    \n",
    "    # Arguments like data location and hyper-parameters are passed from SageMaker to your script\n",
    "    # via command line arguments and/or environment variables. You can use Python's built-in\n",
    "    # argparse module to parse them:\n",
    "    print(\"Parsing training arguments\")\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # RandomForest hyperparameters\n",
    "    parser.add_argument(\"--n_estimators\", type=int, default=10)\n",
    "    parser.add_argument(\"--min_samples_leaf\", type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--test\", type=str, default=os.environ.get(\"SM_CHANNEL_TEST\"))\n",
    "    parser.add_argument(\"--train_file\", type=str, default=\"train.csv\")\n",
    "    parser.add_argument(\"--test_file\", type=str, default=\"test.csv\")\n",
    "    parser.add_argument(\"--features\", type=str)  # explicitly name which features to use\n",
    "    parser.add_argument(\"--target_variable\", type=str)  # name the column to be used as target\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    # -- DATA PREPARATION --\n",
    "    # Load the data from the local folder(s) SageMaker pointed us to:\n",
    "    print(\"Reading data\")\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    test_df = pd.read_csv(os.path.join(args.test, args.test_file))\n",
    "\n",
    "    print(\"Building training and testing datasets\")\n",
    "    X_train = train_df[args.features.split()]\n",
    "    X_test = test_df[args.features.split()]\n",
    "    y_train = train_df[args.target_variable]\n",
    "    y_test = test_df[args.target_variable]\n",
    "\n",
    "    # -- MODEL TRAINING --\n",
    "    print(\"Training model\")\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=args.n_estimators,\n",
    "        min_samples_leaf=args.min_samples_leaf,\n",
    "        n_jobs=-1)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # -- MODEL EVALUATION --\n",
    "    print(\"Testing model\")\n",
    "    abs_err = np.abs(model.predict(X_test) - y_test)\n",
    "    # Output metrics to the console (in this case, percentile absolute errors):\n",
    "    for q in [10, 50, 90]:\n",
    "        print(f\"AE-at-{q}th-percentile: {np.percentile(a=abs_err, q=q)}\")\n",
    "\n",
    "    # -- SAVE THE MODEL --\n",
    "    # ...To the specific folder SageMaker pointed us to:\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print(f\"model saved at {path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local training\n",
    "\n",
    "Since configuration is by command line arguments, we can test our training script locally before uploading to a SageMaker training job.\n",
    "\n",
    "> ⚠️ **Note:** This is good for quick, functional tests of your script against small sample datasets... But once you're confident your script *functionally* works, you probably want to move your experiments to reproduceable, trackable, SageMaker training jobs. Be aware that the libraries in your notebook kernel may not exactly match the container image you configure for the training job later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing training arguments\n",
      "Reading data\n",
      "Building training and testing datasets\n",
      "Training model\n",
      "Testing model\n",
      "AE-at-10th-percentile: 0.033123459488771885\n",
      "AE-at-50th-percentile: 0.2175907057680858\n",
      "AE-at-90th-percentile: 0.7986210757558617\n",
      "model saved at model/model.joblib\n"
     ]
    }
   ],
   "source": [
    "!python src/main.py \\\n",
    "    --n_estimators 100 \\\n",
    "    --min_samples_leaf 10 \\\n",
    "    --model_dir model/ \\\n",
    "    --train data/train \\\n",
    "    --test data/test \\\n",
    "    --features 'MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude' \\\n",
    "    --target_variable target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc        0\n",
       "HouseAge      0\n",
       "AveRooms      0\n",
       "AveBedrms     0\n",
       "Population    0\n",
       "AveOccup      0\n",
       "Latitude      0\n",
       "Longitude     0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Training\n",
    "\n",
    "To run your script in a training job, first we need to upload the data somewhere SageMaker can access it: Typically this will be [Amazon S3](https://aws.amazon.com/s3/).\n",
    "\n",
    "### Creating data input \"channels\" (copy to S3)\n",
    "\n",
    "Note that the number and naming of multiple data \"channels\" for SageMaker is up to you: You don't need to have exactly 2, and they don't need to be called \"train\" and \"test\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set URI: s3://sagemaker-us-east-1-547283773376/sm101/sklearn-cali/train/train.csv\n",
      "Test set URI: s3://sagemaker-us-east-1-547283773376/sm101/sklearn-cali/test/test.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_s3uri = sess.upload_data(\n",
    "    path=\"data/train/train.csv\",  # Local source\n",
    "    bucket=bucket,\n",
    "    key_prefix=\"sm101/sklearn-cali/train\",  # Destination path in S3 bucket\n",
    ")\n",
    "\n",
    "test_data_s3uri = sess.upload_data(\n",
    "    path=\"data/test/test.csv\",  # Local source\n",
    "    bucket=bucket,\n",
    "    key_prefix=\"sm101/sklearn-cali/test\",  # Destination path in S3 bucket\n",
    ")\n",
    "\n",
    "print(\"Train set URI:\", train_data_s3uri)\n",
    "print(\"Test set URI:\", test_data_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_s3uri = 's3://sagemaker-us-east-1-547283773376/sm101/sklearn-cali/train/train.csv'\n",
    "train_data_s3uri = 's3://sagemaker-us-east-1-547283773376/sm101/sklearn-cali/test/test.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching a training job with the Python SDK\n",
    "\n",
    "With the data uploaded and script prepared, you're ready to configure your SageMaker training job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "# We use the Estimator from the SageMaker Python SDK\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "\n",
    "sklearn_estimator = SKLearn(\n",
    "    entry_point=\"main.py\",\n",
    "    source_dir=\"src\",  # To upload the whole folder - or instead set entry_point=\"src/main.py\"\n",
    "    role=sagemaker.get_execution_role(),  # Use same IAM role as notebook is currently using\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m4.xlarge\",\n",
    "    framework_version=\"1.0-1\",\n",
    "    base_job_name=\"rf-scikit\",\n",
    "    metric_definitions=[\n",
    "        # SageMaker can extract metrics from your console logs via Regular Expressions:\n",
    "        {\"Name\": \"median-AE\", \"Regex\": \"AE-at-50th-percentile: ([0-9.]+).*$\"},\n",
    "    ],\n",
    "    hyperparameters={\n",
    "        \"n_estimators\": 100,\n",
    "        \"min_samples_leaf\": 3,\n",
    "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n",
    "        \"target_variable\": \"target\",\n",
    "        # SageMaker data channels are always folders. Even if you point to a particular object\n",
    "        # S3URI, you'll need to either: Properly support loading folder inputs in your script; or\n",
    "        # use extra configuration parameters to identify specific filename(s):\n",
    "        \"train_file\": \"train.csv\",\n",
    "        \"test_file\": \"test.csv\",\n",
    "    },\n",
    "    # Optional settings to run with SageMaker Managed Spot:\n",
    "    #max_run=20*60,  # Maximum allowed active runtime (in seconds)\n",
    "    use_spot_instances=False,  # Use spot instances to reduce cost\n",
    "    #max_wait=30*60,  # Maximum clock time (including spot delays)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: rf-scikit-2024-01-05-12-59-49-007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n",
      "2024-01-05 12:59:49 Starting - Starting the training job...\n",
      "2024-01-05 13:00:05 Starting - Preparing the instances for training.........\n",
      "2024-01-05 13:01:25 Downloading - Downloading input data...\n",
      "2024-01-05 13:02:06 Downloading - Downloading the training image......\n",
      "2024-01-05 13:03:01 Training - Training image download completed. Training in progress..\u001b[34m2024-01-05 13:03:17,778 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:17,782 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:17,785 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:17,803 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,076 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,080 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,103 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,107 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,132 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,135 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,157 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"test\": \"/opt/ml/input/data/test\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"features\": \"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\n",
      "        \"min_samples_leaf\": 3,\n",
      "        \"n_estimators\": 100,\n",
      "        \"target_variable\": \"target\",\n",
      "        \"test_file\": \"test.csv\",\n",
      "        \"train_file\": \"train.csv\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"test\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m4.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"rf-scikit-2024-01-05-12-59-49-007\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-547283773376/rf-scikit-2024-01-05-12-59-49-007/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"main\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"main.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"min_samples_leaf\":3,\"n_estimators\":100,\"target_variable\":\"target\",\"test_file\":\"test.csv\",\"train_file\":\"train.csv\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=main.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m4.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=main\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-547283773376/rf-scikit-2024-01-05-12-59-49-007/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m4.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"features\":\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"min_samples_leaf\":3,\"n_estimators\":100,\"target_variable\":\"target\",\"test_file\":\"test.csv\",\"train_file\":\"train.csv\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"rf-scikit-2024-01-05-12-59-49-007\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-547283773376/rf-scikit-2024-01-05-12-59-49-007/source/sourcedir.tar.gz\",\"module_name\":\"main\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"main.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--features\",\"MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\",\"--min_samples_leaf\",\"3\",\"--n_estimators\",\"100\",\"--target_variable\",\"target\",\"--test_file\",\"test.csv\",\"--train_file\",\"train.csv\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_FEATURES=MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude\u001b[0m\n",
      "\u001b[34mSM_HP_MIN_SAMPLES_LEAF=3\u001b[0m\n",
      "\u001b[34mSM_HP_N_ESTIMATORS=100\u001b[0m\n",
      "\u001b[34mSM_HP_TARGET_VARIABLE=target\u001b[0m\n",
      "\u001b[34mSM_HP_TEST_FILE=test.csv\u001b[0m\n",
      "\u001b[34mSM_HP_TRAIN_FILE=train.csv\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/miniconda3/bin/python main.py --features MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude --min_samples_leaf 3 --n_estimators 100 --target_variable target --test_file test.csv --train_file train.csv\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,158 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:18,159 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mParsing training arguments\u001b[0m\n",
      "\u001b[34mReading data\u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"main.py\", line 45, in <module>\n",
      "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 686, in read_csv\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 452, in _read\n",
      "    parser = TextFileReader(fp_or_buf, **kwds)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 946, in __init__\n",
      "    self._make_engine(self.engine)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 1178, in _make_engine\n",
      "    self._engine = CParserWrapper(self.f, **self.options)\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/pandas/io/parsers.py\", line 2008, in __init__\n",
      "    self._reader = parsers.TextReader(src, **kwds)\n",
      "  File \"pandas/_libs/parsers.pyx\", line 382, in pandas._libs.parsers.TextReader.__cinit__\n",
      "  File \"pandas/_libs/parsers.pyx\", line 674, in pandas._libs.parsers.TextReader._setup_parser_source\u001b[0m\n",
      "\u001b[34mFileNotFoundError: [Errno 2] No such file or directory: '/opt/ml/input/data/train/train.csv'\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:19,336 sagemaker-containers ERROR    Reporting training FAILURE\u001b[0m\n",
      "\u001b[34m2024-01-05 13:03:19,336 sagemaker-containers ERROR    framework error: \u001b[0m\n",
      "\u001b[34mTraceback (most recent call last):\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n",
      "    entrypoint()\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n",
      "    train(environment.Environment())\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 31, in train\n",
      "    entry_point.run(uri=training_environment.module_dir,\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/entry_point.py\", line 108, in run\n",
      "    return runner.get(runner_type, user_entry_point, args, env_vars, extra_opts).run(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 424, in run\n",
      "    process = check_error(\n",
      "  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 335, in check_error\n",
      "    raise error_class(\u001b[0m\n",
      "\u001b[34msagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python main.py --features MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude --min_samples_leaf 3 --n_estimators 100 --target_variable target --test_file test.csv --train_file train.csv\"\u001b[0m\n",
      "\u001b[34mExecuteUserScriptError:\u001b[0m\n",
      "\u001b[34mExitCode 1\u001b[0m\n",
      "\u001b[34mErrorMessage \"\"\u001b[0m\n",
      "\u001b[34mCommand \"/miniconda3/bin/python main.py --features MedInc HouseAge AveRooms AveBedrms Population AveOccup Latitude Longitude --min_samples_leaf 3 --n_estimators 100 --target_variable target --test_file test.csv --train_file train.csv\"\u001b[0m\n",
      "\n",
      "2024-01-05 13:03:33 Uploading - Uploading generated training model\n",
      "2024-01-05 13:03:33 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error for Training job rf-scikit-2024-01-05-12-59-49-007: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n    train(environment.Environment())\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 31, in train\n    entry_point.run(uri=training_environment.module_dir,\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/entry_point.py\", line 108, in run\n    return runner.get(runner_type, user_entry_point, args, env_vars, extra_opts).run(\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 424, in run\n    process = check_error(\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 335, in check_error\n    raise error_class(\nsagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\nExitCode 1\nErro",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msklearn_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data_s3uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_data_s3uri\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/workflow/pipeline_context.py:346\u001b[0m, in \u001b[0;36mrunnable_by_pipeline.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m context\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _StepArguments(retrieve_caller_name(self_instance), run_func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:1322\u001b[0m, in \u001b[0;36mEstimatorBase.fit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjobs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlatest_training_job)\n\u001b[1;32m   1321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 1322\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlatest_training_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/estimator.py:2605\u001b[0m, in \u001b[0;36m_TrainingJob.wait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m   2603\u001b[0m \u001b[38;5;66;03m# If logs are requested, call logs_for_jobs.\u001b[39;00m\n\u001b[1;32m   2604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m logs \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 2605\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlogs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2606\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session\u001b[38;5;241m.\u001b[39mwait_for_job(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_name)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:5450\u001b[0m, in \u001b[0;36mSession.logs_for_job\u001b[0;34m(self, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   5429\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlogs_for_job\u001b[39m(\u001b[38;5;28mself\u001b[39m, job_name, wait\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, poll\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, log_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll\u001b[39m\u001b[38;5;124m\"\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   5430\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Display logs for a given training job, optionally tailing them until job is complete.\u001b[39;00m\n\u001b[1;32m   5431\u001b[0m \n\u001b[1;32m   5432\u001b[0m \u001b[38;5;124;03m    If the output is a tty or a Jupyter cell, it will be color-coded\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5448\u001b[0m \u001b[38;5;124;03m        exceptions.UnexpectedStatusException: If waiting and the training job fails.\u001b[39;00m\n\u001b[1;32m   5449\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5450\u001b[0m     \u001b[43m_logs_for_job\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboto_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7464\u001b[0m, in \u001b[0;36m_logs_for_job\u001b[0;34m(boto_session, job_name, wait, poll, log_type, timeout)\u001b[0m\n\u001b[1;32m   7461\u001b[0m             last_profiler_rule_statuses \u001b[38;5;241m=\u001b[39m profiler_rule_statuses\n\u001b[1;32m   7463\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 7464\u001b[0m     \u001b[43m_check_job_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTrainingJobStatus\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   7465\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dot:\n\u001b[1;32m   7466\u001b[0m         \u001b[38;5;28mprint\u001b[39m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sagemaker/session.py:7517\u001b[0m, in \u001b[0;36m_check_job_status\u001b[0;34m(job, desc, status_key_name)\u001b[0m\n\u001b[1;32m   7511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   7512\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   7513\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   7514\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   7515\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   7516\u001b[0m     )\n\u001b[0;32m-> 7517\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   7518\u001b[0m     message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   7519\u001b[0m     allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStopped\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   7520\u001b[0m     actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   7521\u001b[0m )\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error for Training job rf-scikit-2024-01-05-12-59-49-007: Failed. Reason: AlgorithmError: framework error: \nTraceback (most recent call last):\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_containers/_trainer.py\", line 84, in train\n    entrypoint()\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 39, in main\n    train(environment.Environment())\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_sklearn_container/training.py\", line 31, in train\n    entry_point.run(uri=training_environment.module_dir,\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/entry_point.py\", line 108, in run\n    return runner.get(runner_type, user_entry_point, args, env_vars, extra_opts).run(\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 424, in run\n    process = check_error(\n  File \"/miniconda3/lib/python3.8/site-packages/sagemaker_training/process.py\", line 335, in check_error\n    raise error_class(\nsagemaker_training.errors.ExecuteUserScriptError: ExecuteUserScriptError:\nExitCode 1\nErro"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.fit({\"train\": train_data_s3uri, \"test\": test_data_s3uri}, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the training job that we ran is very \"light\", due to the very small dataset. As such, running locally on the notebook instance results in a faster execution time, compared to SageMaker. SageMaker takes longer time to run the job because it has to provision the training infrastructure. Since this example training job not very resource-intensive, the infrastructure provisioning process adds more overhead, compared to the training job itself. \n",
    "\n",
    "In a real situation, where datasets are large, running on SageMaker can considerably speed up the execution process - and help us optimize costs, by keeping this interactive notebook environment modest and spinning up more powerful training job resources on-demand.\n",
    "\n",
    "Note that this training job *did not run here on the notebook itself*. You'll be able to see the history in the [AWS Console for SageMaker - Training Jobs tab](https://console.aws.amazon.com/sagemaker/home?#/jobs) and also the [SageMaker Studio Experiments and Trials UI](https://docs.aws.amazon.com/sagemaker/latest/dg/experiments-view-compare.html).\n",
    "\n",
    "> ℹ️ **Tip:** There's **no need to re-run** a training job if your notebook kernel restarts or the estimator state is lost for some other reason... You can just *attach* to a previous training job by name - for example:\n",
    ">\n",
    "> ```python\n",
    "> estimator = SKLearn.attach(\"rf-scikit-2025-01-01-00-00-00-000\")\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to a real-time endpoint\n",
    "\n",
    "### Deploy with Python SDK\n",
    "\n",
    "It's possible to deploy a trained `Estimator` to a SageMaker endpoint for real-time inference in one line of code, with `Estimator.deploy(...)` - which implicitly creates a SageMaker [Model](https://console.aws.amazon.com/sagemaker/home?#/models), [Endpoint Configuration](https://console.aws.amazon.com/sagemaker/home?#/endpointConfig), and [Endpoint](https://console.aws.amazon.com/sagemaker/home?#/endpoints).\n",
    "\n",
    "For more fine-grained control though, you can choose to create a `Model` object through the SageMaker Python SDK - referencing the `model.tar.gz` produced on Amazon S3 by the training job. This would allow us to, for example:\n",
    "\n",
    "- Modify environment variables or the Python files used between training and inference\n",
    "- Import a model trained outside SageMaker that's been packaged to a compatible `model.tar.gz` on Amazon S3\n",
    "\n",
    "We'll demonstrate the longer route here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-12-16 12:37:41 Starting - Preparing the instances for training\n",
      "2023-12-16 12:37:41 Downloading - Downloading the training image\n",
      "2023-12-16 12:37:41 Training - Training image download completed. Training in progress.\n",
      "2023-12-16 12:37:41 Uploading - Uploading generated training model\n",
      "2023-12-16 12:37:41 Completed - Training job completed\n",
      "Model artifact saved at: s3://sagemaker-us-east-1-547283773376/rf-scikit-2023-12-16-12-33-03-991/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "sklearn_estimator.latest_training_job.wait(logs=\"None\")  # Check the job is finished\n",
    "\n",
    "# describe() here is equivalent to low-level boto3 SageMaker describe_training_job\n",
    "job_desc = sklearn_estimator.latest_training_job.describe()\n",
    "model_s3uri = job_desc[\"ModelArtifacts\"][\"S3ModelArtifacts\"]\n",
    "\n",
    "print(\"Model artifact saved at:\", model_s3uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.sklearn.model import SKLearnModel\n",
    "\n",
    "model = SKLearnModel(\n",
    "    model_data=model_s3uri,\n",
    "    framework_version=\"1.0-1\",\n",
    "    py_version=\"py3\",\n",
    "    role=sagemaker.get_execution_role(),\n",
    "    entry_point=\"src/main.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = sklearn_estimator.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model.transformer(testX.drop('target',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = model.deploy(\n",
    "    instance_type=\"ml.c5.large\",\n",
    "    initial_instance_count=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realtime inference\n",
    "\n",
    "The [Predictor](https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html) class from the SageMaker Python SDK provides a Python wrapper around the endpoint which also handles (configurable) de/serialization of the request and response.\n",
    "\n",
    "Alternatively for clients which cannot use the SageMaker Python SDK (for example non-Python clients, or Python environments where the PyPI [sagemaker](https://pypi.org/project/sagemaker/) package can't be installed for some reason): The general AWS SDKs can be used to call the lower-level [SageMaker InvokeEndpoint API](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_runtime_InvokeEndpoint.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the SKLearnPredictor does the serialization from pandas for us\n",
    "print(predictor.predict(testX[data.feature_names]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete endpoint\n",
    "\n",
    "While training job infrastructure is started on-demand and terminated as soon as the job stops, endpoints are live until we turn them off. Delete unused endpoints to prevent ongoing costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Batch inference\n",
    "\n",
    "Above we saw how you can deploy your trained model to a real-time API, But what if you want to process a whole batch of data at once? There's no need to manually orchestrate sending this data through an endpoint: You can use [SageMaker Batch Transform](https://docs.aws.amazon.com/sagemaker/latest/dg/batch-transform.html).\n",
    "\n",
    "Like with training, your input data for a batch transform job needs to be accessible to SageMaker (i.e. uploaded to Amazon S3) and the result will be stored to S3. The compute infrastructure spun up for the job will be released as soon as the data is processed.\n",
    "\n",
    "Unlike with training, the input data in S3 needs to match the format your model expects for *inference*. This means we'll need to remove `target`, any unused features, and also column headers (although we could have instead overridden [input_fn](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#process-input) to make our model handle more input shapes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "testX[data.feature_names].to_csv(\"data/transform_input.csv\", header=False, index=False)\n",
    "\n",
    "transform_input_s3uri = sess.upload_data(\n",
    "    path=\"data/transform_input.csv\",  # Local source\n",
    "    bucket=bucket,\n",
    "    key_prefix=\"sm101/sklearn\",  # Destination path in S3 bucket\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the input data uploaded, you're ready to run a transform job using the `model` from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer = model.transformer(\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    # Input Parameters:\n",
    "    strategy=\"MultiRecord\",  # Batch multiple records per request to the endpoint\n",
    "    max_payload=2,  # Max 2MB payload per request\n",
    "    max_concurrent_transforms=2,  # 2 concurrent request threads per instance\n",
    "    # Output Parameters:\n",
    "    output_path=f\"s3://{bucket}/sm101/sklearn-transforms\",\n",
    "    accept=\"text/csv\",  # Request CSV output format\n",
    "    assemble_with=\"Line\",  # Records in CSV output are newline-separated\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transformer.transform(\n",
    "    transform_input_s3uri,\n",
    "    content_type=\"text/csv\",  # Input files are CSV format\n",
    "    split_type=\"Line\",  # Interpret each line of the CSV as a separate record\n",
    "    join_source=\"Input\",  # Bring input features through to the output file\n",
    "    wait=True,  # Keep this notebook blocked until the job completes\n",
    "    logs=True,  # Stream logs to the notebook\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each input object in S3, Batch Transform will generate a similar object under the output folder with `.out` appended to the file name. In our simple example, there was just one input CSV so there will be one `csv.out` result file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "job_desc = sm_boto3.describe_transform_job(TransformJobName=transformer.latest_transform_job.name)\n",
    "output_s3uri = job_desc[\"TransformOutput\"][\"S3OutputPath\"]\n",
    "\n",
    "# pd.read_csv() can take an \"s3://.../.../\" folder, but doesn't like that our Batch Transform\n",
    "# results have .csv.out extension instead of .csv: So instead manually specify which file we want:\n",
    "!echo \"Output folder contents:\" && aws s3 ls {output_s3uri}/\n",
    "\n",
    "input_filename = transform_input_s3uri.rpartition(\"/\")[2]\n",
    "output_file_s3uri = f\"{output_s3uri}/{input_filename}.out\"\n",
    "\n",
    "print(f\"\\nReading {output_file_s3uri} from S3\")\n",
    "pd.read_csv(output_file_s3uri, names=data.feature_names + [\"prediction\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "In this notebook, we saw an example of:\n",
    "\n",
    "- Running your own Scikit-Learn-based model training script as a SageMaker training job, with configurable parameters and output accuracy metrics\n",
    "- Deploying the trained model to a real-time inference API\n",
    "- Using the model for batch inference\n",
    "\n",
    "SageMaker took care of the model serving stack for us with no boilerplate code required: Just define [override functions](https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/using_sklearn.html#sagemaker-scikit-learn-model-server) if needed (like `input_fn` and `model_fn`) to customize the default behaviour. At training time, our script read parameters from the command line arguments and environment variables provided through SageMaker - and loaded data from local folder because download from S3 is taken care of by SageMaker too.\n",
    "\n",
    "By using the SageMaker APIs (instead of just working locally in the notebook), we can improve the traceability and reproducibility of experiments; optimize our compute resource usage; and accelerate the path from trained model to production deployment."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
